{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"swapping.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"g61NvPdD7bNY","colab_type":"code","colab":{}},"cell_type":"code","source":["import os\n","import string\n","import pandas as pd\n","import spacy\n","import re\n","from unidecode import unidecode\n","from collections import defaultdict"],"execution_count":0,"outputs":[]},{"metadata":{"id":"M73dzJvq7bNf","colab_type":"code","colab":{}},"cell_type":"code","source":["en = spacy.load('en')\n","nlp = spacy.load('en_core_web_sm')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2QMlBOmX7bNi","colab_type":"code","colab":{}},"cell_type":"code","source":["directory = '/Users/jaewonhyun/Downloads/stories/'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xtzVm_fR7bNl","colab_type":"code","colab":{}},"cell_type":"code","source":["genderDirectory = '/Users/jaewonhyun/Downloads/'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JmwnU4Nr7bNp","colab_type":"code","colab":{}},"cell_type":"code","source":["# load doc into memory\n","def load_doc(filename):\n","    # open the file as read only\n","    file = open(filename, 'r', encoding='utf-8-sig')\n","    # read all text\n","    text = file.read()\n","    # close the file\n","    file.close()\n","    return text"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3Uija6RB7bNt","colab_type":"code","colab":{}},"cell_type":"code","source":["def preprocess_file(filepath, output_path):\n","    \"\"\"\n","    Preprocesses a file by splitting it into sentences and tokenizing it\n","    \"\"\"\n","    files = os.listdir(filepath)\n","    random.seed(6)\n","    sample_list = random.sample(files, round(0.01*len(files)))\n","    \n","    genderWords = load_doc(genderDirectory+'female_word_file.txt').split('\\n')\n","    genderWords += load_doc(genderDirectory+'male_word_file.txt').split('\\n')\n","    genderWords = [ w.lower() for w in genderWords if len(w)>0 ]\n","    unique_words = set(['her', 'his', 'him', 'hers'])\n","    herhishim = {'her':{'dobj': 'him', 'poss': 'his'}}\n","    hisherhers = {'his':{'attr': 'hers', 'poss': 'her'}}\n","    hers = {'hers':'his'}\n","    him = {'him':'her'}\n","    \n","    all_noun_pairs = load_doc(genderDirectory+'noun_pairs.txt').split('\\n')\n","    female_male_noun_pairs = {}\n","    male_female_noun_pairs = {}\n","    all_pairs = set()\n","    for pair in all_noun_pairs:\n","        female_male = pair.split(\", \")\n","        female_male_noun_pairs[female_male[0].lower()] = female_male[1].lower()\n","        male_female_noun_pairs[female_male[1].lower()] = female_male[0].lower()\n","        all_pairs.add(female_male[0].lower())\n","        all_pairs.add(female_male[1].lower())\n","    \n","    all_pairs.add(\"hers\")\n","    all_pairs.add(\"her\")\n","    all_pairs.add(\"him\")\n","    all_pairs.add(\"his\")\n","    \n","    sentences = []\n","    for file in sample_list:\n","        # Open file\n","        try:\n","            with open(filepath+file, 'r') as f:\n","                text = f.read()\n","        except UnicodeDecodeError as e:\n","            try:\n","                # Account for some files that may be encoded with ISO-8859-1\n","                with open(file, 'r', encoding='iso-8859-1') as f:\n","                    text = f.read()\n","            except UnicodeDecodeError as e:\n","                msg = \"Could not open {}: {}\".format(file, str(e))\n","                raise Exception(msg)\n","\n","        # Remove any additional information e.g. \"@highlights\"\n","        main_text_body = text.split('\\n@')[0]\n","        \n","        # Split up lines, and then break up lines into sentences\n","        \n","        for line in main_text_body.split('\\n\\n'):\n","            sentences += list(en(line.strip('\\n')).sents)\n","            \n","        special_sentences = []\n","        rest = []\n","        \n","    sentences = [sentence.text for sentence in sentences]\n","    sentences = [sentence.replace(\"\\n\",\"\") for sentence in sentences]\n","    sentences = [sentence.replace(\"\\xa0\",\"\") for sentence in sentences]\n","    sentences = [sentence.replace(r\"\\u200\",\"\") for sentence in sentences]\n","    sentences = set([sentence.lower() for sentence in sentences])\n","        \n","    for sentence in sentences:\n","        if sentence:\n","            found = False\n","            found_word = \"\"\n","            for word in genderWords:\n","                if word in sentence.lower():\n","                    found = True\n","                    found_word = word\n","                    break\n","                \n","            if found:\n","                special_sentences.append(sentence)\n","            else:\n","                rest.append(sentence)\n","                    \n","    print(special_sentences)\n","    swapped = []\n","    for current in rest:\n","        sentence = current[:]\n","        checking = False\n","        labeled = nlp(sentence)\n","        ents = set()\n","        herhishimhers = {}\n","        \n","        index = 0\n","        for ent in labeled:\n","            if ent.pos_ == \"PROPN\":\n","                ents.add(ent)\n","            if ent.text in unique_words:\n","                herhishimhers[index] = ent.dep_\n","            if ent.text not in string.punctuation:\n","                index+=1\n","        \n","        split = sentence.split()\n","        for i in range(len(split)):\n","            if split[i] in all_pairs:\n","                if i < len(split)-1 and split[i+1] in ents:\n","                    continue\n","                else:\n","                    if split[i].lower() in herhishimhers:\n","                        dep = herhishimhers[i]\n","                        if split[i].lower() in herhishim:\n","                            if split[i].istitle():\n","                                split[i] = herhishim['her'][dep].capitalize()\n","                            else:\n","                                split[i] = herhishim['her'][dep]\n","                        elif split[i].lower() in hisherhers:\n","                            if split[i].istitle():\n","                                split[i] = hisherhers['his'][dep].capitalize()\n","                            else:\n","                                split[i] = hisherhers['his'][dep]\n","                        elif split[i].lower() in hers:\n","                            if split[i].istitle():\n","                                split[i] = hers[split[i].lower()].capitalize()\n","                            else:\n","                                split[i] = hers[split[i].lower()]\n","                        elif split[i].lower() in him:\n","                            if split[i].istitle():\n","                                splist[i] = him[split[i].lower()].capitalize()\n","                            else:\n","                                split[i] = him[split[i].lower()]\n","                    elif split[i].lower() in female_male_noun_pairs:\n","                        if split[i].istitle():\n","                            split[i] = female_male_noun_pairs[split[i].lower()].capitalize()\n","                        else:\n","                            split[i] = female_male_noun_pairs[split[i].lower()]\n","                    elif split[i].lower() in male_female_noun_pairs:\n","                        if split[i].istitle():\n","                            split[i] = male_female_noun_pairs[split[i].lower()].capitalize()\n","                        else:\n","                            split[i] = male_female_noun_pairs[split[i].lower()]\n","        newsentence = \" \".join(split)\n","        newsentence = newsentence.capitalize()\n","\n","        swapped.append(newsentence)\n","            \n","    res = swapped + special_sentences + rest\n","    \n","    with open(\"/Users/jaewonhyun/Downloads/output.txt\", 'w') as f:\n","        for item in rest:\n","            f.write(item+\"\\n\")\n","\n","    return res"],"execution_count":0,"outputs":[]},{"metadata":{"id":"niaTdwf27bNx","colab_type":"code","colab":{}},"cell_type":"code","source":["df = preprocess_file(directory, genderDirectory)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bnhJ2zdl7bN0","colab_type":"code","colab":{},"outputId":"8ba1fd9d-7b55-4fcc-bdac-cc8363a659d5"},"cell_type":"code","source":["example = \"prostate cancer\"\n","sentence = \"he has prostate cancer\"\n","if example in sentence:\n","    print(True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["True\n"],"name":"stdout"}]},{"metadata":{"id":"qRHRnWJL7bN6","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}